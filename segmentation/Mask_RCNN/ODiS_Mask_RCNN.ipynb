{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g18o4KEOWV0D",
    "tags": []
   },
   "source": [
    "# Check GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nJJLBoBql_x",
    "outputId": "c804a4f6-8f58-4ddd-c009-8e53b60ead3f"
   },
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVV_LmsfWpps",
    "tags": []
   },
   "source": [
    "# One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3h4u4nDWxZX",
    "outputId": "8192e195-7bef-4541-f8ee-eeba4c305765"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/matterport/Mask_RCNN.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79C65LP3qrxo",
    "tags": []
   },
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APgZQ9rF2c7i",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import datetime\n",
    "import skimage.io\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Important directories of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, \"datasets\", \"satellite\")\n",
    "TRAIN_IMG_DIR = os.path.join(DATASET_DIR, \"train_images\")\n",
    "VAL_IMG_DIR = os.path.join(DATASET_DIR, \"val_images\")\n",
    "TRAIN_ANNOT_DIR = os.path.join(DATASET_DIR, \"mask\" , \"train_mask_annotations\")\n",
    "VAL_ANNOT_DIR = os.path.join(DATASET_DIR, \"mask\", \"val_mask_annotations\")\n",
    "\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model\n",
    "\n",
    "\n",
    "#import satellite\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import skimage\n",
    "print(skimage.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0grlX-i8_6a"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "class SatelliteConfig(Config):\n",
    "    \"\"\"Configuration for training on the satellite segmentation dataset.\"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"satellite\"\n",
    "\n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    GPU_COUNT = 2\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # Background + body + solar_panel + antenna\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "\n",
    "    #DETECTION_MIN_CONFIDENCE = 0.5\n",
    "\n",
    "\n",
    "class SatelliteInferenceConfig(SatelliteConfig):\n",
    "    # Set batch size to 1 to run one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Don't resize imager for inferencing\n",
    "    IMAGE_RESIZE_MODE = \"none\"\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkkRi_fD8_o_"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class SatelliteDataset(utils.Dataset):\n",
    "\n",
    "    def load_satellite(self, dataset_type_dir, mask_dir):\n",
    "\n",
    "        self.add_class(\"satellite\", 1, \"body\")\n",
    "        self.add_class(\"satellite\", 2, \"solar_panel\")\n",
    "        self.add_class(\"satellite\", 3, \"antenna\")\n",
    "\n",
    "        file_names = os.listdir(dataset_type_dir)\n",
    "        image_ids = []\n",
    "        for file_name in file_names:\n",
    "            if file_name.endswith(\".png\"):\n",
    "                image_ids.append(file_name)\n",
    "        #print(image_ids)\n",
    "        \n",
    "        for image_id in image_ids:\n",
    "            temp_str = image_id.replace('.png','')\n",
    "            temp_str = temp_str + '_mask'\n",
    "            mask_dir_img_id = os.path.join(mask_dir, temp_str)\n",
    "            #print(mask_dir_img_id)\n",
    "            self.add_image(\n",
    "                \"satellite\",\n",
    "                image_id=image_id,\n",
    "                path=os.path.join(dataset_type_dir, image_id),\n",
    "                mask_dir_img_id = mask_dir_img_id\n",
    "                )\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        # Get mask directory from image path\n",
    "        mask_dir_img_id = info['mask_dir_img_id']\n",
    "        #mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"masks\")\n",
    "        # Read mask files from .png image\n",
    "        #print(image_id, mask_dir_img_id)\n",
    "        mask = []\n",
    "        class_ids = []\n",
    "\n",
    "        # mask_dir_img_id_list = os.listdir(mask_dir_img_id)\n",
    "        for f in next(os.walk(mask_dir_img_id))[2]:\n",
    "        # for f in mask_dir_img_id_list:\n",
    "            if f.endswith(\".png\"):\n",
    "                if 'body' in f:\n",
    "                    class_ids.append(1)\n",
    "                if 'solar_panel' in f:\n",
    "                    class_ids.append(2)\n",
    "                if 'antenna' in f:\n",
    "                    class_ids.append(3)\n",
    "                m = skimage.io.imread(os.path.join(mask_dir_img_id, f)).astype(np.bool)\n",
    "                mask.append(m)\n",
    "        mask = np.stack(mask, axis=-1)\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID, we return an array of ones\n",
    "        #------------------------------------------------------------\n",
    "\n",
    "        return mask, np.array(class_ids)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"satellite\":\n",
    "            return info[\"id\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSN7KhjC2c3m"
   },
   "outputs": [],
   "source": [
    "config = SatelliteConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIqvT2-f2c0N",
    "outputId": "e2e2e8b3-a455-4362-ae0c-506b5bae65f6"
   },
   "outputs": [],
   "source": [
    "dataset_train = SatelliteDataset()\n",
    "dataset_train.load_satellite(TRAIN_IMG_DIR, TRAIN_ANNOT_DIR)\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_train.num_classes))\n",
    "for i, info in enumerate(dataset_train.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNS-UUnU8QL-",
    "outputId": "43711a43-8f6f-461a-900d-f88470a813fb"
   },
   "outputs": [],
   "source": [
    "dataset_val = SatelliteDataset()\n",
    "dataset_val.load_satellite(VAL_IMG_DIR, VAL_ANNOT_DIR)\n",
    "# Must call before using the dataset\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YL0bbQqrBJF",
    "tags": []
   },
   "source": [
    "# Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "BGt1hdz5taaX",
    "outputId": "ca450952-6ca4-48ef-803c-8cff84c5631f"
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "#image_ids = dataset.image_ids\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 7)\n",
    "#print(image_ids)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    print(image_id)\n",
    "    #plt.imshow(image)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "B0KpCefYgb0g",
    "outputId": "41439831-8130-406f-8fc0-2637390d8cc9"
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "#image_ids = dataset.image_ids\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 7)\n",
    "#print(image_ids)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_val.load_image(image_id)\n",
    "    print(image_id)\n",
    "    #plt.imshow(image)\n",
    "    mask, class_ids = dataset_val.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_val.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3EkeKxe85XV",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Create Model & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgsQ-27V85XW",
    "outputId": "62386698-bc7f-4b0a-955d-bf80a0854de0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RgM79vZ85XW",
    "outputId": "d01c4591-3b00-4d54-ed82-a8b759648afc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_with = \"last\"  \n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "  \n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    last_saved_model = model.find_last()\n",
    "    print(last_saved_model)\n",
    "    model.load_weights(last_saved_model, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=40,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_O003Ez1wnvS"
   },
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Configuration\n",
    "config_infer = SatelliteInferenceConfig()\n",
    "config_infer.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# Only inference mode is supported right now\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tensorflow.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                              model_dir=MODEL_DIR,\n",
    "                              config=config_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to a specific weights file\n",
    "# weights_path = os.path.join(ROOT_DIR, \"mask_rcnn_satellite_0025.h5\")\n",
    "\n",
    "# Or, load the last model you trained\n",
    "weights_path = model.find_last()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, config_infer, image_id, use_mini_mask=False)\n",
    "info = dataset_val.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       dataset_val.image_reference(image_id)))\n",
    "print(\"Original image shape: \", modellib.parse_image_meta(image_meta[np.newaxis,...])[\"original_image_shape\"][0])\n",
    "\n",
    "# Run object detection\n",
    "results = model.detect_molded(np.expand_dims(image, 0), np.expand_dims(image_meta, 0), verbose=1)\n",
    "\n",
    "# Display results\n",
    "r = results[0]\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "# Compute AP over range 0.5 to 0.95 and print it\n",
    "utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
    "                       r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "                       verbose=1)\n",
    "\n",
    "visualize.display_differences(\n",
    "    image,\n",
    "    gt_bbox, gt_class_id, gt_mask,\n",
    "    r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "    dataset.class_names, ax=get_ax(),\n",
    "    show_box=False, show_mask=False,\n",
    "    iou_threshold=0.5, score_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot Training Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir path/to/log --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteInferenceConfig(SatelliteConfig):\n",
    "    # Set batch size to 1 to run one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Configuration\n",
    "config_infer = SatelliteInferenceConfig()\n",
    "# config_infer.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tensorflow.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"path/to/trained_model\"\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = SatelliteDataset()\n",
    "dataset_val.load_satellite(VAL_IMG_DIR, VAL_ANNOT_DIR)\n",
    "# Must call before using the dataset\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "print(image_id)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, config_infer, image_id, use_mini_mask=False)\n",
    "info = dataset_val.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       dataset_val.image_reference(image_id)))\n",
    "\n",
    "\n",
    "# Run object detection\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "ax = get_ax(1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tmp0 = r['masks']\n",
    "# print(mask_tmp0, type(mask_tmp0))\n",
    "print(mask_tmp0.shape, mask_tmp0.size)\n",
    "print(image.shape, image.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2,2, figsize = (16,6))\n",
    "\n",
    "axis[0, 0].imshow(mask_tmp0[:,:,0])\n",
    "axis[0, 1].imshow(mask_tmp0[:,:,1])\n",
    "axis[1, 0].imshow(mask_tmp0[:,:,2])\n",
    "axis[1, 1].imshow(mask_tmp0[:,:,3])\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "mask_predi = mask_tmp0[:,:,0] + mask_tmp0[:,:,1] + mask_tmp0[:,:,2] +  mask_tmp0[:,:,3]\n",
    "# mask_predi = cv2.cvtColor(mask_predi, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(mask_predi, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SatelliteDataset()\n",
    "dataset_train.load_satellite(TRAIN_IMG_DIR, TRAIN_ANNOT_DIR)\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_train.num_classes))\n",
    "for i, info in enumerate(dataset_train.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_train.image_ids)\n",
    "print(image_id)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_train, config_infer, image_id, use_mini_mask=False)\n",
    "info = dataset_train.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       dataset_train.image_reference(image_id)))\n",
    "\n",
    "# Run object detection\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "ax = get_ax(1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"/path/to/trained_model\"\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run object detection on own images\n",
    "import cv2\n",
    "sat_test_img = os.path.join(ROOT_DIR, \"sat_test_img\", \"0_26_hr.png\")\n",
    "# sat_test_img = cv2.resize(sat_test_img, (1024, 1024))\n",
    "# image = plt.imread(sat_test_img)\n",
    "image = cv2.imread(sat_test_img)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "ax = get_ax(1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/inx/data_partition/Projects/ODiS/Space-Intelligence-Vision-and-Analytics/segmentation/Mask_RCNN\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m         masks_comb \u001b[38;5;241m=\u001b[39m masks_comb \u001b[38;5;241m+\u001b[39m masks_all[:,:,i]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m masks_comb\n\u001b[0;32m---> 20\u001b[0m masks_all \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m masks_comb \u001b[38;5;241m=\u001b[39m Comb_Masks(masks_all)\n\u001b[1;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mimsave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_pred_1028_teeeest.png\u001b[39m\u001b[38;5;124m'\u001b[39m, masks_comb, cmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "import cv2\n",
    "\n",
    "def Comb_Masks(masks_all):\n",
    "    \n",
    "    # print(masks_all, type(masks_all))\n",
    "    print(masks_all.shape, masks_all.size, masks_all.dtype)\n",
    "    print(image.shape, image.size, image.dtype)\n",
    "\n",
    "    W, H, N_m = masks_all.shape\n",
    "    # print(W, H, N_m)\n",
    "\n",
    "    masks_comb = np.zeros((W,H), dtype = bool)\n",
    "    # print(mask_comb)\n",
    "    for i in range(N_m):\n",
    "        masks_comb = masks_comb + masks_all[:,:,i]\n",
    "\n",
    "    return masks_comb\n",
    "\n",
    "masks_all = r['masks']\n",
    "masks_comb = Comb_Masks(masks_all)\n",
    "plt.imsave('mask_pred_1028_teeeest.png', masks_comb, cmap = 'gray')\n",
    "# cv2.imwrite('mask_pred_1028_teeeest.png', masks_comb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataset run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = SatelliteDataset()\n",
    "dataset_val.load_satellite(VAL_IMG_DIR, VAL_ANNOT_DIR)\n",
    "# Must call before using the dataset\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('val_masks_pred_BnW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cwd = os.getcwd()\n",
    "# cwd\n",
    "%cd Val_masks_pred_BnW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "def Comb_Masks(masks_all, image_name):\n",
    "    \n",
    "    # print(masks_all, type(masks_all))\n",
    "    print(masks_all.shape, masks_all.size, masks_all.dtype)\n",
    "    print(image.shape, image.size, image.dtype)\n",
    "\n",
    "    W, H, N_m = masks_all.shape\n",
    "    # print(W, H, N_m)\n",
    "\n",
    "    masks_comb = np.zeros((W,H), dtype = bool)\n",
    "    # print(mask_comb)\n",
    "    for i in range(N_m):\n",
    "        masks_comb = masks_comb + masks_all[:,:,i]\n",
    "        \n",
    "    image_name = image_name.replace('.png','')\n",
    "    plt.imsave(f'{image_name}_mask.png', masks_comb, cmap = 'gray')\n",
    "    \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"something.png\"\n",
    "print(str1)\n",
    "# print(str1 - '.png')\n",
    "str1 = str1.replace('.png','')\n",
    "print(str1)\n",
    "str1_1 = str1 + '_mask.png'\n",
    "print(str1_1)\n",
    "#or\n",
    "str1_2 = f\"{str1}_mask.png\"\n",
    "print(str1_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# info = dataset_val.image_info[image_id]\n",
    "# print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "#                                        dataset_val.image_reference(image_id)))\n",
    "for image_id in dataset_val.image_ids:\n",
    "\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config_infer, image_id, use_mini_mask=False)\n",
    "    info = dataset_val.image_info[image_id]\n",
    "    \n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    masks_all = r['masks']\n",
    "    \n",
    "    image_name = info[\"id\"]\n",
    "    Comb_Masks(masks_all, image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole folder\n",
    "VAL_IMG_DIR_list = os.listdir(VAL_IMG_DIR)\n",
    "len(VAL_IMG_DIR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "for image_name in VAL_IMG_DIR_list:\n",
    "\n",
    "    image_path = os.path.join(VAL_IMG_DIR, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "    # Display results\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    masks_all = r['masks']\n",
    "    Comb_Masks(masks_all, image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "\n",
    "import cv2\n",
    "\n",
    "mask_pred = mask_tmp0[:,:,0] + mask_tmp0[:,:,1] + mask_tmp0[:,:,2]   # True/False addition\n",
    "print(mask_pred.shape)\n",
    "print(mask_pred)\n",
    "# mask_predi = cv2.cvtColor(mask_predi, cv2.COLOR_BGR2RGB)\n",
    "plt.imsave('mask_pred_1028.png', mask_predi, cmap = 'gray')\n",
    "plt.imshow(mask_predi, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(image, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, title=\"\",\n",
    "                      figsize=(16, 16), ax=None,\n",
    "                      show_mask=True, show_bbox=True,\n",
    "                      colors=None, captions=None):\n",
    "    \"\"\"\n",
    "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "    masks: [height, width, num_instances]\n",
    "    class_ids: [num_instances]\n",
    "    class_names: list of class names of the dataset\n",
    "    scores: (optional) confidence scores for each box\n",
    "    title: (optional) Figure title\n",
    "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
    "    figsize: (optional) the size of the image\n",
    "    colors: (optional) An array or colors to use with each object\n",
    "    captions: (optional) A list of strings to use as captions for each object\n",
    "    \"\"\"\n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    # If no axis is passed, create one and automatically call show()\n",
    "    auto_show = False\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "        auto_show = True\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or visualize.random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "    ax.set_ylim(height + 10, -10)\n",
    "    ax.set_xlim(-10, width + 10)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    for i in range(N):\n",
    "        color = colors[i]\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        if show_bbox:\n",
    "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
    "                                alpha=0.7, linestyle=\"dashed\",\n",
    "                                edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(p)\n",
    "\n",
    "        # Label\n",
    "        if not captions:\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i] if scores is not None else None\n",
    "            label = class_names[class_id]\n",
    "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        else:\n",
    "            caption = captions[i]\n",
    "        ax.text(x1, y1 + 8, caption,\n",
    "                color='w', size=11, backgroundcolor=\"none\")\n",
    "\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        if show_mask:\n",
    "            masked_image = visualize.apply_mask(masked_image, mask, color)\n",
    "\n",
    "        # Mask Polygon\n",
    "        # Pad to ensure proper polygons for masks that touch image edges.\n",
    "        padded_mask = np.zeros(\n",
    "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = visualize.find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "            # Subtract the padding and flip (y, x) to (x, y)\n",
    "            verts = np.fliplr(verts) - 1\n",
    "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
    "            ax.add_patch(p)\n",
    "        return masked_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run object detection on own images\n",
    "\n",
    "sat_test_img = os.path.join(ROOT_DIR, \"sat_test_img\", \"sat_img_12.jpg\")\n",
    "image = plt.imread(sat_test_img)\n",
    "\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "ax = get_ax(1)\n",
    "r = results[0]\n",
    "# masked_image = \n",
    "display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "\n",
    "# plt.imshow(masked_image)\n",
    "# plt.imsave(\"infer0.png\", masked_image)\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteInferenceConfig(SatelliteConfig):\n",
    "    # Set batch size to 1 to run one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Don't resize imager for inferencing\n",
    "    #IMAGE_RESIZE_MODE = \"none\"\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    #RPN_NMS_THRESHOLD = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Configuration\n",
    "config_infer = SatelliteInferenceConfig()\n",
    "config_infer.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = SatelliteDataset()\n",
    "dataset_val.load_satellite(VAL_IMG_DIR, VAL_ANNOT_DIR)\n",
    "# Must call before using the dataset\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "batch_size = 1\n",
    "# Create model in inference mode\n",
    "with tensorflow.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config_infer)\n",
    "    \n",
    "weights_path = \"/home/deepesh/ODiS_Mask_RCNN/Mask_RCNN/logs/satellite20220310T0032/mask_rcnn_satellite_0024.h5\"\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "CLASS_NAMES_MASKRCNN = ['body','solar_panel','antenna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_dict():\n",
    "    all_colors = visualize.random_colors(3)\n",
    "    color_dict = {}\n",
    "    i = 0\n",
    "    for c in CLASS_NAMES_MASKRCNN:\n",
    "        if not c in color_dict:\n",
    "            color_dict[c] = all_colors[i]\n",
    "            i = i+1\n",
    "    color_dict[\"background\"] = (0,0,0)\n",
    "    return color_dict\n",
    "\n",
    "COLOR_MAP = get_color_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_color_image(labels):\n",
    "    # Adds color defined by the dataset colormap to the label.\n",
    "    h,w = labels.shape\n",
    "    img = np.zeros([h,w,3])\n",
    "    img = np.zeros((h,w),dtype=(float,3))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            img[i][j] = np.array(COLOR_MAP[CLASS_NAMES_MASKRCNN[labels[i][j]]])        \n",
    "    img = img*255\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "def combine_masks(img, result):\n",
    "    boxes = result['rois']\n",
    "    masks = result['masks']\n",
    "    class_ids = result['class_ids']\n",
    "  \n",
    "    N = boxes.shape[0]\n",
    "    h,w,c = img.shape\n",
    "    seg_map = np.zeros((h,w))\n",
    "    for i in range(N):\n",
    "        mask = masks[:, :, i]\n",
    "        mask = mask.astype(np.uint8)\n",
    "        seg_map = seg_map + mask*class_ids[i]\n",
    "  \n",
    "    return seg_map.astype(np.uint8)\n",
    "\n",
    "def merge_images(foreground, background, alpha=0.3):\n",
    "    out_img = np.zeros(background.shape,dtype=background.dtype)\n",
    "    out_img[:,:,:] = (alpha * background[:,:,:]) + ((1-alpha) * foreground[:,:,:])\n",
    "    return out_img\n",
    "\n",
    "############################################################################################################################\n",
    "\n",
    "def display_instances(image, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, title=\"\",\n",
    "                      figsize=(16, 16), ax=None,\n",
    "                      show_mask=True, show_bbox=True,\n",
    "                      colors=None, captions=None):\n",
    "    \"\"\"\n",
    "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "    masks: [height, width, num_instances]\n",
    "    class_ids: [num_instances]\n",
    "    class_names: list of class names of the dataset\n",
    "    scores: (optional) confidence scores for each box\n",
    "    title: (optional) Figure title\n",
    "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
    "    figsize: (optional) the size of the image\n",
    "    colors: (optional) An array or colors to use with each object\n",
    "    captions: (optional) A list of strings to use as captions for each object\n",
    "    \"\"\"\n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    # If no axis is passed, create one and automatically call show()\n",
    "    auto_show = False\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "        auto_show = True\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or visualize.random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "    ax.set_ylim(height + 10, -10)\n",
    "    ax.set_xlim(-10, width + 10)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    for i in range(N):\n",
    "        color = colors[i]\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        if show_bbox:\n",
    "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
    "                                alpha=0.7, linestyle=\"dashed\",\n",
    "                                edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(p)\n",
    "\n",
    "        # Label\n",
    "        if not captions:\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i] if scores is not None else None\n",
    "            label = class_names[class_id]\n",
    "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        else:\n",
    "            caption = captions[i]\n",
    "        ax.text(x1, y1 + 8, caption,\n",
    "                color='w', size=11, backgroundcolor=\"none\")\n",
    "\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        if show_mask:\n",
    "            masked_image = visualize.apply_mask(masked_image, mask, color)\n",
    "\n",
    "        # Mask Polygon\n",
    "        # Pad to ensure proper polygons for masks that touch image edges.\n",
    "        padded_mask = np.zeros(\n",
    "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = visualize.find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "            # Subtract the padding and flip (y, x) to (x, y)\n",
    "            verts = np.fliplr(verts) - 1\n",
    "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
    "            ax.add_patch(p)\n",
    "        return masked_image\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "def get_masked_image(image, result):\n",
    "    \"\"\"\n",
    "    Applies masks from the results to the given image\n",
    "  \n",
    "    \"\"\"\n",
    "#     boxes = result['rois']\n",
    "#     masks = result['masks']\n",
    "  \n",
    "#     N = boxes.shape[0]\n",
    "#     if not N:\n",
    "#         print(\"\\n*** No instances to display *** \\n\")\n",
    "\n",
    "    # colors = visualize.random_colors(N)\n",
    "    # masked_image = image.astype(np.uint32).copy()\n",
    "\n",
    "#     for i in range(N):\n",
    "#         color = colors[i]\n",
    "\n",
    "#         # Mask\n",
    "#         mask = masks[:, :, i]\n",
    "#         # masked_image = visualize.apply_mask(masked_image, mask, color)\n",
    "    ax = get_ax(1)\n",
    "    r = result\n",
    "    masked_image = display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset_val.class_names, r['scores'], ax=ax,)\n",
    "    \n",
    "    return masked_image.astype(np.uint8)\n",
    "\n",
    "def print_fps(video):\n",
    "    # Find OpenCV version\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "        print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "    else :\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "\n",
    "\n",
    "def make_video(outvid, images=None, fps=30, size=None,\n",
    "               is_color=True, format=\"FMP4\"):\n",
    "    \"\"\"\n",
    "    Create a video from a list of images.\n",
    " \n",
    "    @param      outvid      output video\n",
    "    @param      images      list of images to use in the video\n",
    "    @param      fps         frame per second\n",
    "    @param      size        size of each frame\n",
    "    @param      is_color    color\n",
    "    @param      format      see http://www.fourcc.org/codecs.php\n",
    "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    " \n",
    "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
    "    By default, the video will have the size of the first image.\n",
    "    It will resize every image to this size before adding them to the video.\n",
    "    \"\"\"\n",
    "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "    fourcc = VideoWriter_fourcc(*format)\n",
    "    vid = None\n",
    "    for image in images:\n",
    "        if not os.path.exists(image):\n",
    "            raise FileNotFoundError(image)\n",
    "        img = imread(image)\n",
    "        if vid is None:\n",
    "            if size is None:\n",
    "                size = img.shape[1], img.shape[0]\n",
    "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
    "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
    "            img = resize(img, size)\n",
    "        vid.write(img)\n",
    "    vid.release()\n",
    "    return vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = os.path.join(ROOT_DIR, \"sat_test_vid\")\n",
    "VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"sat_infer_vid\")\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(VIDEO_SAVE_DIR):\n",
    "        os.makedirs(VIDEO_SAVE_DIR)\n",
    "except OSError:\n",
    "    print ('Error: Creating directory of data')\n",
    "\n",
    "# os.chdir('./sat_test_img')\n",
    "\n",
    "# from google.colab import files\n",
    "# uploads = files.upload()\n",
    "\n",
    "# os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(os.path.join(VIDEO_DIR, \"sat_vid_1.mp4\"))\n",
    "\n",
    "print_fps(capture)\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(VIDEO_SAVE_DIR):\n",
    "        os.makedirs(VIDEO_SAVE_DIR)\n",
    "except OSError:\n",
    "    print ('Error: Creating directory of data')\n",
    "frames = []\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    # Bail out when the video file ends\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Save each frame of the video to a list\n",
    "    frame_count += 1\n",
    "    frames.append(frame)\n",
    "    print('frame_count :{0}'.format(frame_count))\n",
    "    if len(frames) == batch_size:\n",
    "        results = model.detect(frames, verbose=0)\n",
    "        # print(results)\n",
    "        # print(results[0])\n",
    "        # print(len(results))\n",
    "        print('Predicted')\n",
    "        for i, item in enumerate(zip(frames, results)):\n",
    "            frame = item[0]\n",
    "            r = item[1]\n",
    "            # print(r)\n",
    "            #seg_map = combine_masks(frame, r)\n",
    "            #seg_image = label_to_color_image(seg_map)\n",
    "            #frame = merge_images(seg_image, frame)\n",
    "            frame = get_masked_image(frame, r)\n",
    "            name = '{0}.jpg'.format(frame_count + i - batch_size)\n",
    "            name = os.path.join(VIDEO_SAVE_DIR, name)\n",
    "            print(type(frame), frame.size, frame.shape)\n",
    "            plt.imshow(frame)\n",
    "            plt.imsave(name, frame)\n",
    "            # cv2.imwrite(name, frame)\n",
    "        # Clear the frames array to start the next batch\n",
    "        frames = []\n",
    "\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "images = list(glob.iglob(os.path.join(VIDEO_SAVE_DIR, '*.*')))\n",
    "# Sort the images by integer index\n",
    "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
    "\n",
    "outvid = os.path.join(VIDEO_DIR, \"final.mp4\")\n",
    "make_video(outvid, images, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ODiS_Mask-RCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
